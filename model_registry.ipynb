{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5118413e",
   "metadata": {},
   "source": [
    "# Experiment on model registration and promotion\n",
    "By Siwarat Laoprom 65070501052\n",
    "\n",
    "## Prerequisites:\n",
    " - MLflow installed (pip install mlflow)\n",
    " - Pandas installed (pip install pandas)\n",
    " - Training data available (green_tripdata_2021-03.csv)\n",
    " - SQLite database for tracking (mlflow.db)\n",
    "\n",
    "## Thing to do before running the script:\n",
    " - Training the models and log the artifacts to MLflow (Using the same script in my custom duration-prediction.ipynb)\n",
    "\n",
    " ![Experiments](experiments.png)\n",
    "\n",
    "\n",
    "## Now we can register the models to the model registry following the steps below:\n",
    "1. Search for the experiment id of the experiment that you want to register the models to.\n",
    "2. Search for the run id of the run that you want to register the models to.\n",
    "3. Register the models to the model registry using the run id and the experiment id.\n",
    "4. Promote the models to production or staging using the model registry API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T15:49:37.372682Z",
     "start_time": "2025-03-16T15:49:36.072369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30d9f40bd30bb2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T15:49:53.248289Z",
     "start_time": "2025-03-16T15:49:52.886555Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='/home/chogerlate/Documents/github/cpe393/cpe393-mlflow/mlruns/1', creation_time=1743007869912, experiment_id='1', last_update_time=1743007869912, lifecycle_stage='active', name='mlops_nyc_taxi', tags={}>,\n",
       " <Experiment: artifact_location='/home/chogerlate/Documents/github/cpe393/cpe393-mlflow/mlruns/0', creation_time=1743007869903, experiment_id='0', last_update_time=1743007869903, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "client.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e7965358afe3200b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T15:50:54.398721Z",
     "start_time": "2025-03-16T15:50:54.382003Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string=\"metrics.rmse < 100\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse ASC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52681452eed1388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T15:50:55.055949Z",
     "start_time": "2025-03-16T15:50:55.053464Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 4f903ee4a20c4e2a8a787af7317f169f, rmse: 5.1175\n",
      "run id: f6b0c0d304eb43bb9a491daa2c682193, rmse: 5.2133\n",
      "run id: eb3a41a62ec74ca78f8ac38c4047c863, rmse: 5.2344\n",
      "run id: 386144f58ff243dfbf19fd9452e46b00, rmse: 5.2351\n",
      "run id: 2a225d8062374225a7d538b4c09cb31b, rmse: 5.2556\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adae478d",
   "metadata": {},
   "source": [
    "Register models to staging and production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1364b30512c67b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T15:51:27.949595Z",
     "start_time": "2025-03-16T15:51:27.945794Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted registered model: nyc-taxi-regressor\n"
     ]
    }
   ],
   "source": [
    "# Delete registered model by name\n",
    "# model_name = \"nyc-taxi-regressor\"\n",
    "# try:\n",
    "#     client.delete_registered_model(name=model_name)\n",
    "#     print(f\"Deleted registered model: {model_name}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error deleting model {model_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de69106",
   "metadata": {},
   "source": [
    "# Model Registration\n",
    "For this example, I will register the models to the model registry using the run id and the experiment id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "181d90df1e449da3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version: 1\n",
      "Model version: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'nyc-taxi-regressor'.\n",
      "Created version '1' of model 'nyc-taxi-regressor'.\n",
      "Registered model 'nyc-taxi-regressor' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'nyc-taxi-regressor'.\n"
     ]
    }
   ],
   "source": [
    "# linear: b8f327fb5ffd41699ed7ac217e216f11\n",
    "# xgboost: f6b0c0d304eb43bb9a491daa2c682193\n",
    "\n",
    "registered_models = [\n",
    "        {\n",
    "            \"name\": \"nyc-taxi-regressor\",\n",
    "            \"run_id\": \"b8f327fb5ffd41699ed7ac217e216f11\",\n",
    "            \"alias\": \"production\",\n",
    "            \"tag\": {\n",
    "                \"model_type\": \"linear\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"nyc-taxi-regressor\",\n",
    "            \"run_id\": \"f6b0c0d304eb43bb9a491daa2c682193\",\n",
    "            \"alias\": \"staging\",\n",
    "            \"tag\": {\n",
    "                \"model_type\": \"xgboost\"\n",
    "            }\n",
    "        }\n",
    "]\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "for model in registered_models:\n",
    "    model_name = model[\"name\"]\n",
    "    run_id = model[\"run_id\"]\n",
    "    alias = model[\"alias\"]\n",
    "    tags = model[\"tag\"]\n",
    "    \n",
    "    model_uri = f\"runs:/{run_id}/models_mlflow\"\n",
    "    model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "    model_version = model_details.version\n",
    "    print(f\"Model version: {model_version}\")\n",
    "    \n",
    "    client.set_registered_model_alias(\n",
    "        name=model_name,\n",
    "        alias=alias,\n",
    "        version=model_version\n",
    "    )\n",
    "    \n",
    "    for key, value in tags.items():\n",
    "        client.set_model_version_tag(\n",
    "            name=model_name,\n",
    "            version=model_version,\n",
    "            key=key,\n",
    "            value=value\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fbcf37",
   "metadata": {},
   "source": [
    "## The Registration Result\n",
    "![Model Registry](model_registry.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dda14c",
   "metadata": {},
   "source": [
    "# Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a18941abe32fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Comparing versions and selecting the new \"Production\" model\n",
    "In the last section, we will retrieve models registered in the model registry and compare their performance on an unseen test set. The idea is to simulate the scenario in which a deployment engineer has to interact with the model registry to decide whether to update the model version that is in production or not.\n",
    "\n",
    "These are the steps:\n",
    "\n",
    "Load the test dataset, which corresponds to the NYC Green Taxi data from the month of March 2021.\n",
    "Download the DictVectorizer that was fitted using the training data and saved to MLflow as an artifact, and load it with pickle.\n",
    "Preprocess the test set using the DictVectorizer so we can properly feed the regressors.\n",
    "Make predictions on the test set using the model versions that are currently in the \"Staging\" and \"Production\" stages, and compare their performance.\n",
    "Based on the results, update the \"Production\" model version accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24f0d1",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9276b72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://github.com/DataTalksCl]\u001b8\u001b7\u001b[2A\u001b[1Ggreen_tripdata_2021-   0% [<=>                           ]       0          B/s\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JHTTP response 302  [https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2021-03.csv.gz]\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Ggreen_tripdata_2021-   0% [ <=>                          ]       0          B/s\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JAdding URL: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/b1479513-aea0-4591-b22f-d3f075aee3f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250326%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250326T200803Z&X-Amz-Expires=300&X-Amz-Signature=798ed5e59e0e4687418eec068d9c0e88e8bf6731f7fe27d5afea534f3aa47cac&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2021-03.csv.gz&response-content-type=application%2Foctet-stream\n",
      "\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[2A\u001b[1G\u001b[27G[https://objects.githubusercont]\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 0  Bytes: 0  [0 B/s] Re]\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JSaving 'green_tripdata_2021-03.csv.gz'\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Ggreen_tripdata_2021- 100% [=============================>]    1.45M    --.-KB/s\u001b8\u001b7\u001b[1S\u001b[3A\u001b[1G\u001b[0JHTTP response 200  [https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/b1479513-aea0-4591-b22f-d3f075aee3f8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250326%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250326T200803Z&X-Amz-Expires=300&X-Amz-Signature=798ed5e59e0e4687418eec068d9c0e88e8bf6731f7fe27d5afea534f3aa47cac&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2021-03.csv.gz&response-content-type=application%2Foctet-stream]\n",
      "\u001b8\u001b7\u001b[2A\u001b[1Ggreen_tripdata_2021- 100% [=============================>]    1.45M    --.-KB/s\u001b8\u001b7\u001b[1A\u001b[1G\u001b[27G[Files: 1  Bytes: 1.45M [700.39]\u001b8\u001b[m\u001b[m\u001b[m\u001b[m"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2021-03.csv.gz\n",
    "# Extract the downloaded file\n",
    "!gzip -d green_tripdata_2021-03.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6c3ebc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aliases': [],\n",
      "    'creation_timestamp': 1743022390211,\n",
      "    'current_stage': 'None',\n",
      "    'description': None,\n",
      "    'last_updated_timestamp': 1743022390211,\n",
      "    'name': 'nyc-taxi-regressor',\n",
      "    'run_id': 'f6b0c0d304eb43bb9a491daa2c682193',\n",
      "    'run_link': None,\n",
      "    'source': '/home/chogerlate/Documents/github/cpe393/cpe393-mlflow/mlruns/1/f6b0c0d304eb43bb9a491daa2c682193/artifacts/models_mlflow',\n",
      "    'status': 'READY',\n",
      "    'status_message': None,\n",
      "    'tags': {'model_type': 'xgboost'},\n",
      "    'user_id': None,\n",
      "    'version': 2}\n",
      "{   'aliases': [],\n",
      "    'creation_timestamp': 1743022390138,\n",
      "    'current_stage': 'None',\n",
      "    'description': None,\n",
      "    'last_updated_timestamp': 1743022390138,\n",
      "    'name': 'nyc-taxi-regressor',\n",
      "    'run_id': 'b8f327fb5ffd41699ed7ac217e216f11',\n",
      "    'run_link': None,\n",
      "    'source': '/home/chogerlate/Documents/github/cpe393/cpe393-mlflow/mlruns/1/b8f327fb5ffd41699ed7ac217e216f11/artifacts/models_mlflow',\n",
      "    'status': 'READY',\n",
      "    'status_message': None,\n",
      "    'tags': {'model_type': 'linear'},\n",
      "    'user_id': None,\n",
      "    'version': 1}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "client = MlflowClient()\n",
    "for mv in client.search_model_versions(\"name='nyc-taxi-regressor'\"):\n",
    "    pprint(dict(mv), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03333644",
   "metadata": {},
   "source": [
    "# Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "926d36db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_229765/959287776.py:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_data = pd.read_csv('/home/chogerlate/Documents/github/cpe393/cpe393-mlflow/green_tripdata_2021-03.csv')\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 179.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import mlflow\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv('/home/chogerlate/Documents/github/cpe393/cpe393-mlflow/green_tripdata_2021-03.csv')\n",
    "\n",
    "# Preprocess test data (similar to how you processed training data)\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "    df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "    \n",
    "    # Calculate trip duration\n",
    "    df['trip_duration'] = (df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    \n",
    "    # Extract date features\n",
    "    df['pickup_month'] = df['lpep_pickup_datetime'].dt.month\n",
    "    df['pickup_day'] = df['lpep_pickup_datetime'].dt.day\n",
    "    df['pickup_hour'] = df['lpep_pickup_datetime'].dt.hour\n",
    "    df['pickup_dayofweek'] = df['lpep_pickup_datetime'].dt.dayofweek\n",
    "    \n",
    "    # Filter data\n",
    "    df = df[(df['trip_duration'] >= 1) & (df['trip_duration'] <= 60)]\n",
    "    df = df[(df['passenger_count'] > 0) & (df['passenger_count'] < 8)]\n",
    "    df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 100)]\n",
    "    \n",
    "    # Create feature dictionary\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    numerical = ['trip_distance', 'fare_amount', 'passenger_count', 'pickup_hour', 'pickup_dayofweek']\n",
    "    \n",
    "    df_features = df[categorical + numerical].copy()\n",
    "    \n",
    "    # Target variable\n",
    "    y = df['trip_duration'].values\n",
    "    \n",
    "    return df_features, y\n",
    "\n",
    "X_test, y_test = preprocess_data(test_data)\n",
    "\n",
    "# Download and load the DictVectorizer from MLflow\n",
    "# Replace with your actual run_id that contains the DictVectorizer\n",
    "run_id_with_dv = registered_models[0][\"run_id\"]\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "client.download_artifacts(run_id_with_dv, \"preprocessor/preprocessor.b\", \".\")\n",
    "\n",
    "with open(\"preprocessor.b\", \"rb\") as f:\n",
    "    dv = pickle.load(f)\n",
    "\n",
    "# Convert features to dictionary format for the DictVectorizer\n",
    "def convert_to_dict(df, categorical, numerical):\n",
    "    records = df.to_dict(orient='records')\n",
    "    return records\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance', 'fare_amount', 'passenger_count', 'pickup_hour', 'pickup_dayofweek']\n",
    "X_test_dict = convert_to_dict(X_test, categorical, numerical)\n",
    "\n",
    "# Transform test data\n",
    "X_test_processed = dv.transform(X_test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328db54a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "443b1ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production model metrics: {'RMSE': np.float64(13.773066629512336), 'MAE': 12.263384542623728, 'R2': -0.5840609576391043}\n",
      "Staging model metrics: {'RMSE': np.float64(6.469703422286586), 'MAE': 3.957585729163056, 'R2': 0.6504741195437235}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    return {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2}\n",
    "\n",
    "production_metrics = {\"RMSE\": float(\"inf\"), \"MAE\": float(\"inf\"), \"R2\": -float(\"inf\")}\n",
    "staging_metrics = {\"RMSE\": float(\"inf\"), \"MAE\": float(\"inf\"), \"R2\": -float(\"inf\")}\n",
    "\n",
    "try:\n",
    "    production_model = mlflow.pyfunc.load_model(model_uri=\"models:/nyc-taxi-regressor@production\")\n",
    "    production_metrics = evaluate_model(production_model, X_test_processed, y_test)\n",
    "    print(\"Production model metrics:\", production_metrics)\n",
    "except Exception as e:\n",
    "    print(f\"No production model found: {e}\")\n",
    "\n",
    "try:\n",
    "    staging_model = mlflow.pyfunc.load_model(model_uri=\"models:/nyc-taxi-regressor@staging\")\n",
    "    staging_metrics = evaluate_model(staging_model, X_test_processed, y_test)\n",
    "    print(\"Staging model metrics:\", staging_metrics)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading staging model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfaa86",
   "metadata": {},
   "source": [
    "# Promotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "42b54c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staging model performs better. Promoting to production.\n",
      "  Production RMSE: 13.7731\n",
      "  Staging RMSE: 6.4697\n",
      "  Improvement: 7.3034 (53.03%)\n",
      "Removed alias 'production' from version 1\n",
      "Assigned alias 'production' to version 2\n",
      "Model version 1 moved to archive\n"
     ]
    }
   ],
   "source": [
    "def reassign_alias(client, model_name, alias, new_version):\n",
    "    \"\"\"Move an alias from any existing version to a new version\"\"\"\n",
    "    try:\n",
    "        # Check if alias exists on any version\n",
    "        current_version = client.get_model_version_by_alias(model_name, alias)\n",
    "        \n",
    "        # If the alias is already on the target version, do nothing\n",
    "        if current_version.version == new_version:\n",
    "            print(f\"Alias '{alias}' is already assigned to version {new_version}\")\n",
    "            return\n",
    "            \n",
    "        # Delete the alias from its current version\n",
    "        client.delete_registered_model_alias(model_name, alias)\n",
    "        print(f\"Removed alias '{alias}' from version {current_version.version}\")\n",
    "    except Exception:\n",
    "        # Alias doesn't exist yet, which is fine\n",
    "        pass\n",
    "        \n",
    "    # Assign the alias to the new version\n",
    "    client.set_registered_model_alias(model_name, alias, new_version)\n",
    "    print(f\"Assigned alias '{alias}' to version {new_version}\")\n",
    "    \n",
    "# Compare models and promote the better one to production\n",
    "if staging_metrics[\"RMSE\"] < production_metrics[\"RMSE\"]:\n",
    "    print(f\"Staging model performs better. Promoting to production.\")\n",
    "    print(f\"  Production RMSE: {production_metrics['RMSE']:.4f}\")\n",
    "    print(f\"  Staging RMSE: {staging_metrics['RMSE']:.4f}\")\n",
    "    print(f\"  Improvement: {production_metrics['RMSE'] - staging_metrics['RMSE']:.4f} ({(1 - staging_metrics['RMSE']/production_metrics['RMSE']) * 100:.2f}%)\")\n",
    "    \n",
    "    # Get the current production model version\n",
    "    production_version = client.get_model_version_by_alias(\n",
    "        name=\"nyc-taxi-regressor\", \n",
    "        alias=\"production\"\n",
    "    )\n",
    "    \n",
    "    # Get the staging model version\n",
    "    staging_version = client.get_model_version_by_alias(\n",
    "        name=\"nyc-taxi-regressor\", \n",
    "        alias=\"staging\"\n",
    "    )\n",
    "    \n",
    "    reassign_alias(client, \"nyc-taxi-regressor\", \"production\", staging_version.version)\n",
    "    print(f\"Model version {production_version.version} moved to archive\")\n",
    "else:\n",
    "    print(f\"Production model performs better. No promotion needed.\")\n",
    "    print(f\"  Production RMSE: {production_metrics['RMSE']:.4f}\")\n",
    "    print(f\"  Staging RMSE: {staging_metrics['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c8521",
   "metadata": {},
   "source": [
    "## Promotion Result\n",
    "![Promotion](promotion.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
